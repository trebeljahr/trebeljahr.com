---
title: "AI Video Generation, Real-Time Image Generation, and ChipNeMo"
cover:
    src: "/assets/midjourney/a-robot-gardening-a-beautiful-flower-garden.webp"
    alt: "a robot gardening a beautiful flower garden"
    width: 780
    height: 780
excerpt: "Welcome to this edition of Live and Learn. This time with several updates on AI Video Generation, as well as Real-Time Image Generation by StabilityAI, a piece on how companies should think about AI adoption, a summary of the ousting of Sam Altman from OpenAI, and much more‚Ä¶ I hope you enjoy."
tags: ["AI", "genAI", "generative AI", "Stable Diffusion", "Stability AI", "Midjourney", "OpenAI", "Neuralink", "Nvidia", "LLM", "Claude", "Inflection", "Anthropic", "EMU", "Meta", "Sam Altman"]
---

## ‚ú® Quote ‚ú®

> Purpose turns impediments to happiness into *sources* of happiness‚Ää‚Äî‚Ääbecause meaning is our greatest driver of long-term joy.

‚Äì Nik G√∂ke - [(source)](https://nik.art/this-virtual-soldiers-speech-explains-how-to-have-true-purpose-in-life/)

## üñáÔ∏è Links üñáÔ∏è

[**Stable Diffusion Video** by StabilityAI](https://stability.ai/news/stable-video-diffusion-open-ai-video-model). StabililityAI the company behind the open-sourced Stable Diffusion model has released a new AI that can generate videos from text prompts. The results are quite impressive and the model is open-source as well. The main problem right now with text-to-video is that the video length is still really short. Currently, the videos are only 4 seconds each, but soon we will see longer and longer videos, with even better quality. 

[**EMU Text to Video AI** by Meta](https://ai.meta.com/blog/emu-text-to-video-generation-image-editing-research/). Not just Stability AI has been working on generative models that can output videos. Meta has been busy getting this to work too. I think that in 2024 we will see similar jumps in the quality of these video generation models as we saw in the last year with the developments of Midjourney and Dalle-3. Already people are using Runways tools to generate entire videos, but now with more players out there, the adoption will only grow, improving the existing models by giving them more human feedback on the generations that can be incorporated and learned from. Soon, AI-generated videos will be as commonplace as AI-generated images are now. It is crazy to think that this whole ‚Äútrend‚Äù has only taken a bit over a year to play out.

[**Rebuilding Organizational Structures to Deal with the Rise of AI**](https://www.oneusefulthing.org/p/reshaping-the-tree-rebuilding-organizations?publication_id=1180644&post_id=138998139). With all of the changes going on around AI it is important how companies think about and incorporate these new technologies. This post deals with this topic and gives some food for thought on how to improve company processes and truly embrace AI. Most important of all is that the time to utilize AI is now or *too late* since the advantages accrued by people who successfully use these new tools and capabilities will be able to outcompete those who don't. On the same note, I found a [product called Olympia Chat](https://olympia.chat/), while researching this newsletter that is showing the nature of things to come.

[**EMU Edit AI** by Meta](https://emu-edit.metademolab.com/). Another big release from Meta happened these last 2 weeks: A model that allows you to edit images with text prompts. Their demos are mindblowing *and* the model is‚Äìin what amounts to Meta fashion these days‚Äìcompletely open-source. A context-aware, magical editing tool, that just does what you tell it to do, is reality now. 

[**Brain Implant Human Clinical Trials** by Neuralink](https://www.youtube.com/watch?v=z7o39CzHgug). Neuralink recently announced that they got approval for human clinical trials of their brain implants, in a short video clip. This is a huge step forward for them because, if successful, they could use their technology to make the lives of lots of people with severe disabilities much much better.

[**Using LLMs to design better Chips** by Nvidia](https://blogs.nvidia.com/blog/llm-semiconductors-chip-nemo/). In a masterclass example of how to embrace AI to re-imagine workflows and make them more efficient, Nvidia is using its massive knowledge in AI to make their own lives of designing chips easier. They built a custom LLM-based system that acts kinda like CoPilot but for the design of computing hardware instead of code. The whole thing is "only" a fine-tuned, specialized version of LLaMa-2 but it can help their engineers a lot already. Nvidia has made their learnings accessible to others via [their paper](https://d1qx31qr3h6wln.cloudfront.net/publications/ChipNeMo%20%282%29.pdf) and the [NeMo framework](https://www.nvidia.com/en-us/ai-data-science/products/nemo/get-started/?nvid=nv-int-unbr-268853) for finetuning AIs for custom purposes.

[**Real Time Image Generation** by StabilityAI](https://stability.ai/news/stability-ai-sdxl-turbo). Image Generation with Midjourney and tools like it, while impressive, takes time, while you wait until the images have been generated. With this new model from StabilityAI, you can generate images in real-time, which is a huge step forward for the technology. It feels surreal that it can generate what you are typing, faster than you are typing it. And the amount of creative freedom and direction this offers to the generative process is surreal. You can try it out at [Stability AI's clip drop site](https://clipdrop.co/stable-diffusion-turbo). I don't find it quite as fast as they promised, but still, it's insanely quick compared to Midjourney and the output quality is impressive too. 

[**Sam Altman ousted from OpenAI**](https://en.wikipedia.org/wiki/Removal_of_Sam_Altman_from_OpenAI). The Wikipedia summary is accurate and has links to sources and lots and lots of further reading. Even though I followed the whole thing on X as it happened, I enjoyed reading the Wikipedia article as it serves as a good, unspeculative summary of what has happened. A lot of people have lost sleep over this, while it was happening, and still, nobody *really* knows what happened in full detail and *why* Sam Altman was fired after all. Rumors include Q*, an internal research project that might be AGI, Sam Altman abusing the OpenAI name to gain capital for building a competitor to Nvidia, Microsoft planning everything to "buy" OpenAI, OpenAI being a threat to Quoras Poe, which D'Angelo, one of the board members didn't like and therefore staged a "coup" and many many more. At the end of the day, we simply don't know (yet). 

Finally, there were big updates to the foundation models of 2 of OpenAIs competitors: [**Inflection 2** by InflectionAI](https://inflection.ai/inflection-2) and the [**Claude 2** by Anthropic](https://www.anthropic.com/index/claude-2-1) (with a whopping 200k context window!) are now both available. But GPT-4 remains the best foundation model out there, at least for now. 


## üåå Midjourney üåå

![a floating city](/assets/midjourney/a-floating-city.webp) 
![a robot creating another robot](/assets/midjourney/a-robot-creating-another-robot.webp) 
![bioluminescent creatures in the deep](/assets/midjourney/bioluminescent-creatures-in-the-deep.webp) 
![blend-1](/assets/midjourney/blend-1.webp)
![the expanse of technological marvels 2](/assets/midjourney/the-expanse-of-technological-marvels-2.webp) 
![the expanse of technological marvels](/assets/midjourney/the-expanse-of-technological-marvels.webp) 
![vietnamese noodle soup](/assets/midjourney/vietnamese-noodle-soup.webp) 
![wifi lines connecting city scape glow](/assets/midjourney/wifi-lines-connecting-city-scape-glow.webp) 
![winter pond reflection in the mountains at night](/assets/midjourney/winter-pond-reflection-in-the-mountains-at-night.webp)


## üé∂ Song üé∂

**Dog Days Are Over** by Florence and the Machine 

[Youtube Music](https://music.youtube.com/watch?v=v3cgdlHzQDQ) | [Spotify](https://open.spotify.com/track/0QsMzENszoF5DNrx901f8s)

---

That's all for this time. I hope you found this newsletter useful, beautiful, or even both!

Have ideas for improving it? As always [please let me know](https://airtable.com/shro1VeyG4lkNXkx2). 

Cheers,

**‚Äì Rico**
